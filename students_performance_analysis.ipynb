# StudentsPerformance Analysis and Classification
# ===================================================
# This notebook loads the StudentsPerformance.csv dataset,
# preprocesses the data, performs exploratory data analysis,
# trains a Random Forest classifier to predict high math performance,
# and evaluates the model.

# 1. Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score

# 2. Load Data
# ===================================================
# Replace the path with your actual file path if needed
df = pd.read_csv("StudentsPerformance.csv")

# Display the first few rows
print("First 5 rows:")
print(df.head())

# 3. Check for Missing Values
# ===================================================
print("\nMissing values in each column:")
print(df.isnull().sum())

# 4. Encode Categorical Variables
# ===================================================
# Use one-hot encoding for categorical columns
df_encoded = pd.get_dummies(df, columns=[
    "gender", 
    "race/ethnicity", 
    "parental level of education", 
    "lunch", 
    "test preparation course"
], drop_first=True)

print("\nColumns after encoding:")
print(df_encoded.columns)

# 5. Normalize Score Columns
# ===================================================
# Normalize math, reading, and writing scores to [0,1] range
scaler = MinMaxScaler()
score_cols = ["math score", "reading score", "writing score"]
df_encoded[score_cols] = scaler.fit_transform(df_encoded[score_cols])

print("\nFirst 5 rows after normalization:")
print(df_encoded[score_cols].head())

# 6. Exploratory Data Analysis (EDA)
# ===================================================
# Plot distributions of scores
plt.figure(figsize=(12,4))
for i, col in enumerate(score_cols):
    plt.subplot(1, 3, i+1)
    sns.histplot(df[col], bins=20, kde=True)
    plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()

# Plot math score by gender
plt.figure(figsize=(6,4))
sns.boxplot(x="gender", y="math score", data=df)
plt.title("Math Score by Gender")
plt.show()

# 7. Create Classification Target
# ===================================================
# Define 'high_math' as math score >= 70 (before normalization)
# We use the original column from 'df', not scaled
df_encoded['high_math'] = (df['math score'] >= 70).astype(int)
print("\nCount of high_math (target variable):")
print(df_encoded['high_math'].value_counts())

# 8. Split Data
# ===================================================
# Exclude original math score (target is high_math)
X = df_encoded.drop(['high_math'], axis=1)
y = df_encoded['high_math']

# Train/Val/Test split: 70/15/15
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

print(f"\nTrain size: {X_train.shape[0]}, Val size: {X_val.shape[0]}, Test size: {X_test.shape[0]}")

# 9. Train Random Forest Classifier
# ===================================================
# Create and train the model
rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf.fit(X_train, y_train)

# Evaluate on validation set
val_score = rf.score(X_val, y_val)
print(f"\nValidation accuracy: {val_score:.3f}")

# 10. Evaluate Model on Test Set
# ===================================================
y_pred = rf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print("\nConfusion Matrix (Test Set):")
print(cm)
print(f"Precision: {precision:.3f}")
print(f"Recall: {recall:.3f}")

# Plot confusion matrix
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix (Test Set)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# 11. Feature Importance (Optional but Insightful)
# ===================================================
importances = rf.feature_importances_
indices = np.argsort(importances)[-10:] # Top 10 features

plt.figure(figsize=(8,5))
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [X.columns[i] for i in indices])
plt.title('Top 10 Feature Importances')
plt.xlabel('Relative Importance')
plt.show()

# Done!
print("Analysis complete.")
